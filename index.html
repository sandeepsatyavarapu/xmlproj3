<html>
    <head>
         <link rel="stylesheet" href="Style.css">
        <title>XMLPROJECT2</title>
    </head>
    <body>
         <center>
        <h1 style="margin-top: 50px">ENDNOTES</h1>
        </center>
        <p style="text-align: justify">1 &nbsp; &nbsp;The complete dataset can be found at Delve, a machine learning repository and testing environment located at the University of Toronto, Department of Computer Science. The URL is http://www.cs.toronto.edu/~delve.</p>
        <p  style="text-align: justify">2 &nbsp; &nbsp; &nbsp; &nbsp;The algorithm was coded using S-Plus. The programs are available from the authors.</p>
        <p  style="text-align: justify">3 &nbsp; &nbsp; &nbsp; &nbsp;Recent research has established that the model is not limited to acyclic graphs.Direct or indirect cyclic causality may be included in BBNs.</p>
        <p  style="text-align: justify">4 &nbsp; &nbsp; &nbsp; &nbsp;Once again, the example has been created for illustrative purposes and should not be taken too seriously.</p>
        <p  style="text-align: justify">5 &nbsp; &nbsp; &nbsp; &nbsp;The philosophical debate regarding this approach has been going on for centuries.William of Occam (14th century) was one of the first thinkers to discuss the question of whether simpler hypotheses are better than complicated ones. For this reason, this approach goes by the name of <i>Occam’s razor</i> .</p>
        <center>
        <h1>REFERENCES</h1>
        </center>
        <p  style="text-align: justify">Cox, R. T. (1946). Probability, frequency and reasonable expectation.<i> American Journal of Physics, </i>14:1-13.</p>
        <p  style="text-align: justify">DeGroot, M. (1986). <i>Probability and statistics.</i> Reading, MA: Addison Wesley.</p>
        <p  style="text-align: justify">Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised and unsupervised discretization of continuous features, In A. Prieditis and S. Russell (eds.), <i>Proceedings of the Twelfth International Conference on Machine Learning,</i> pp. 194—202. SanFrancisco, CA: Morgan Kaufmann.</p>
        <p  style="text-align: justify">Friedman, N. & Goldzmidt, M. (1999). Learning Bayesian networks with local structure.In M.I. Jordan (ed.),<i> Learning in graphical models.</i> Cambridge, MA: MIT Press.Friedman, N., Geiger, D.,& Goldszmidt, M. (1997). Bayesian network classifiers.<i> Machine Learning, </i>29:131-163.</p>
        <p  style="text-align: justify">Gelman, A., Carlin, J., Stern, H., & Rubin, D. (1995).<i> Bayesian Data Analysis,</i> Chapman & Hall/CRC.</p>
        <p  style="text-align: justify">Heckerman, D., Geiger, D., & Chickering, D. (1994). Learning Bayesian networks: The combination of knowledge and statistical data. Technical Report MSR-TR-94-09,Microsoft Research.</p>
        <p  style="text-align: justify">Janes, E.T. (1996). <i>Probability theory: The logic of science, </i>Fragmentary Edition.Available online at: http://bayes.wustl.edu/etj/prob.html.</p>
        <p  style="text-align: justify">Joachims, T. (1996). A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. Technical Report CMU-CS-96-118, School of Computer Science,Carnegie Mellon University, March.</p>
        <p  style="text-align: justify">Kohavi, R., Becker, B., & Sommerfield, D. (1997). Improving simple Bayes. ECML-97:<i>Proceedings of the Ninth European Conference on Machine Learning.</i></p>
        <p  style="text-align: justify">Lam, W. & Bachus, F. (1994). Learning Bayesian networks: An approach based on the MDL principle<i> Computational Intelligence </i>10(3), 269-293.</p>
        <p  style="text-align: justify">Lauritzen, S. L. & Spiegelhalter. D. J. (1988). Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society, Series B, 50(2):157-224.</p>
        <p  style="text-align: justify">Mitchell. T. (1997). <i>Machine learning.</i> New York: McGraw-Hill.</p>
        <p  style="text-align: justify">Neal, R. M. (1993). <i>Probabilistic inference using Markov Chain Monte Carlo Methods.</i>Technical Report CRG-TR-93-1, Department of Computer Science, University of Toronto.</p>
        <p  style="text-align: justify">Pearl, J. (1988).<i> Probabilistic reasoning in intelligent systems: Networks of plausible inference.</i> San Mateo, CA: Morgan Kaufmann.</p>
        <p  style="text-align: justify">Ramoni, M. & Sebastiani, P. (1999). Bayesian methods for intelligent data analysis. In M.Berthold & D.J. Hand, (eds.), <i>Intelligent data analysis: An introduction. </i>New York: Springer-Verlag.</p>
        <p  style="text-align: justify">Rodriguez, C. (1999).<i> An introduction to Markov Chain Monte Carlo. Available online at:</i> http://omega.albany.edu:8008/cdocs/.</p>
        <p  style="text-align: justify">Sivia, D. (1996). <i>Data analysis: A Bayesian tutorial.</i> Oxford, UK: Oxford Science Publications.</p>
        <p  style="text-align: justify">Van der Gaag, L.C. (1996). Bayesian belief networks: Odds and ends. Technical Report UU-Cs-1996-14, Utretch University.</p>
        <p  style="text-align: justify">Witten, I. & Frank, E. (2000). <i>Data mining: Practical machine learning tools and techniques with Java implementations.</i> San Mateo, CA: Morgan Kaufmann.</p>
        <center>
        <h3 tyle="margin-right:30px;">Chapter XII</h3>
        <h1>Mining Free Text for Structure</h1>
        </center>
        <p style="margin-left:640px;">Vladimir A. Kulyukin</p>
        <p style="margin-left:630px;">Utah State University, USA</p>
        <p style="margin-left:670px;">Robin Burke</p>
        <p style="margin-left:640px;">DePaul University,USA</p>
        <center>
        <h1 style="margin-right:50px;">ABSTRACT</h1>
        </center>
        <p  style="text-align: justify"><i>Knowledge of the structural organization of information in documents can be of significant assistance to information systems that use documents as their knowledge bases. In particular, such knowledge is of use to information retrieval systems that retrieve documents in response to user queries. This chapter presents an approach to mining free-text documents for structure that is qualitative in nature. It complements the statistical and machine-learning approaches, insomuch as the structural organization of information in documents is discovered through mining free text for content markers left behind by document writers. The ultimate objective is to find scalable data mining (DM) solutions for free-text documents in exchange for modest knowledge-engineering requirements. The problem of mining free text for structure is addressed in the context of finding structural components of files of frequently asked questions (FAQs) associated with many USENET newsgroups. The chapter describes a system that mines FAQs for structural components. The chapter concludes with an outline of possible future trends in the structural mining of free text.</i></p>
        <center>
         <h1 style="margin-right:50px;">INTRODUCTION</h1>
        </center>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;When the manager of a mutual fund sits down to write an update of the fund’s prospectus, he does not start his job from scratch. He knows what the fund’s sharehold-ers expect to see in the document and arranges the information accordingly. An inventor, ready to register his idea with the Patent and Trademark Office of the U.S. Department of Commerce, writes it up in accordance with the rules specifying the format of patent submissions. A researcher who wants to submit a paper to a scientific conference must be aware of the format specifications set up by the conference committee. Each of these examples suggests that domains of human activity that produce numerous documents are likely to have standards specifying how information must be presented in them.</p>
        <p>Such standards, or presentation patterns, are a matter of economic necessity; documents whose visual structure reflects their logical organization are much easier to mine for information than unconstrained text. The ability to find the needed content in the document by taking advantage of its structural organization allows the readers to deal with large quantities of data efficiently. For example, when one needs to find out if a person’s name is mentioned in a book, one does not have to read it from cover to cover; going to the index section is a more sensible solution.</p>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Knowledge of the structural organization of information in documents1 can be of significant assistance to information systems that use documents as their knowledge bases. In particular, such knowledge is of use to information retrieval systems (Salton & McGill, 1983) that retrieve documents in response to user queries. For example, an information retrieval system can match a query against the structural components of a document, e.g., sections of an article, and make a retrieval decision based on some combination of matches. More generally, knowledge of the structural organization of information in documents makes it easier to mine those documents for information.</p>
        <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The advent of the World Wide Web and the Internet have resulted in the creation of millions of documents containing unstructured, structured, and semi-structured data. Consequently, research on the automated discovery of structural organization of information in documents has come to the forefront of both information retrieval and natural language processing (Freitag, 1998; Hammer, Garcia-Molina, Cho, Aranha, & Crespo, 1997; Hsu & Chang, 1999; Jacquemin & Bush, 2000; Kushmerick, Weld, & Doorenbos, 1997). Most researchers adhere to numerical approaches of machine learning and information retrieval. Information retrieval approaches view texts as sets of terms, each of which exhibits some form of frequency distribution. By tracking the frequency distributions of terms, one can attempt to partition the document into smaller chunks, thus claiming to have discovered a structural organization of information in a given document. Machine-learning approaches view texts as objects with features whose combinations can be automatically learned by inductive methods.</p>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Powerful as they are, these approaches to mining documents for structure have two major drawbacks. First, statistical computations are based on the idea of statistical significance (Moore & McCabe, 1993). Achieving statistical significance requires large quantities of data. The same is true for machine-learning approaches that require large training sets to reliably learn needed regularities. Since many documents are small in size, the reliable discovery of their structural components using numerical methods alone is problematic. Second, numerical approaches ignore the fact that document writers leave explicit markers of content structure in document texts. The presence of these markers in document texts helps the reader digest the information contained in the document. If these markers are ignored, document texts become much harder to navigate and understand.</p>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This chapter presents an approach to mining free-text documents for structure that is qualitative in nature. It complements the statistical and machine-learning approaches inso much as the structural organization of information in documents is discovered through mining free text for content markers left behind by document writers2 . The ultimate objective is to find scalable data-mining solutions for free-text documents in exchange for modest knowledge-engineering requirements. The approach is based on the following assumptions:</p>
        <ul>
            <p  style="text-align: justify"> <li><b>Economic Necessity.</b> The higher the demand for a class of documents, the greaterthe chances that the presentation of information in those documents adheres to a small set of rigid standards. Mutual fund prospectuses, 10-Q forms, and USENET files of frequently asked questions (FAQs) are but a few examples of document classes that emerged due to economic necessity and whose formats were standardized by consumer demand.</li></p>
            <p  style="text-align: justify"><li><b>Texts As Syntactic Objects.</b>As a source of information, text can be viewed as a syntactic object whose structural organization obeys certain constraints. It is often possible to find the needed content in a document by using the structural organization of its text.</li></p>
            <p  style="text-align: justify"> <li><b> Presentation Consistency.</b> Document writers are consistent in their presentation patterns. They do not change the chosen pattern within a single document. Many of them stick with the same pattern from document to document.</li></p>
            <p  style="text-align: justify"><li><b>Presentation Similarity.</b>The logical components of a document that have the same semantic functionality are likely to be marked in the same or similar fashion within a presentation pattern. For example, many document writers tend to mark headers, tables, sections, bibliographies, etc., in the same or similar ways in document texts.</li></p>

        </ul>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;These assumptions form a theoretical basis of the approach. Collectively, they act as guidelines for researchers and developers who are interested in building free-text datamining tools for individual domains. The rest of the chapter illustrates how these assumptions were applied to mine newsgroups’ expertise.</p>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The rest of the chapter is organized as follows. The next section provides the necessary background and a review of relevant literature. The following three sections constitute the main thrust of the chapter. First, we describe the problem of mining newsgroups’ expertise for answers to frequently asked questions. Second, we state our solution to the problem of mining free text for structure. The problem is addressed in the context of finding structural components of FAQs associated with many USENET newsgroups. Third, we describe an evaluation of our mining approach. In the last two sections, we outline possible future trends in mining text for structure and present our conclusions.</p>
        <center>
        <h1>RELATED WORK</h1>
        </center>
        <p  style="text-align: justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the context of data mining, structural mining of text is the task of partitioning text into components, each of which contains a specific kind of information. For example, if it is known that a given HTML text is a home page, one can design strategies to mine the</p>
    </body>
</html>